{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/abdelrahman/Desktop/RNAseq/src/utils/dev_parse_input.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdelrahman/Desktop/RNAseq/src/utils/dev_parse_input.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mre\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdelrahman/Desktop/RNAseq/src/utils/dev_parse_input.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/abdelrahman/Desktop/RNAseq/src/utils/dev_parse_input.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mglobals\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdelrahman/Desktop/RNAseq/src/utils/dev_parse_input.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/abdelrahman/Desktop/RNAseq/src/utils/dev_parse_input.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/RNAseq/src/utils/globals.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpsutil\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mruntime\u001b[39;00m \u001b[39mimport\u001b[39;00m RunTime\n\u001b[1;32m      6\u001b[0m \u001b[39m# cols\u001b[39;00m\n\u001b[1;32m      7\u001b[0m RED \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[;31;1m\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "from globals import *\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_extension(df):\n",
    "    \"\"\"checks all files have same extension from pandas df, to use in generete sample table function\"\"\"\n",
    "    uniques = df['ext'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        logging.error(f\"{RED}Your input directory has multible fastq file extensions, please check directory.{NC}\")\n",
    "        exit(1)\n",
    "\n",
    "    else:\n",
    "        return uniques\n",
    "\n",
    "def check_PE(df):\n",
    "    \"\"\"checks all files either single or paried ended from pandas df, to use in generete sample table function\"\"\"\n",
    "    uniques = df['PE'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        logging.error(f\"{RED}Your input directory has both Paired and single files, please check directory.{NC}\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        return uniques\n",
    "\n",
    "def check_R(df):\n",
    "    \"\"\"checks all files have same naming patterns from pandas df, to use in generete sample table function\"\"\"\n",
    "    uniques = df['read_num'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        logging.error(f\"{RED}Your input directory has multible fastq file naming patterns, please check directory.{NC}\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        return uniques\n",
    "\n",
    "def check_pattern(df):\n",
    "    \"\"\"checks all files have same naming patterns from pandas df, to use in generete sample table function\"\"\"\n",
    "    uniques = df['matched_pattern'].unique()\n",
    "    if len(uniques) > 1:\n",
    "        logging.error(f\"{RED}Your input directory has multible fastq file naming patterns, please check directory.{NC}\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recogize_pattern(file_name):\n",
    "    # Matches the file name to a pattern\n",
    "    # naming patterns for sample recognition\n",
    "    patterns = {\n",
    "        \"illumina\": \"(((.+)_(S\\d+)_(L00\\d))_(R1|R2|r1|r2|read1|read2)_(00\\d)\\.(fastq\\.gz|fastq|fq\\.gz|fq))\",\n",
    "        \"SRR\": \"(((SRR)(\\d+))(_|\\.)(1|2|R1|R2|r1|r2|read1|read2)\\.(fastq\\.gz|fastq|fq\\.gz|fq))\",\n",
    "        \"general\": \"(((.+))(_|\\.)(1|2|R1|R2|r1|r2|read1|read2)\\.(fastq\\.gz|fastq|fq\\.gz|fq))\"\n",
    "    }\n",
    "    matched_pattern = None\n",
    "    for ptrn_name, pattern in patterns.items():\n",
    "        try:\n",
    "            matched = re.match(pattern, file_name) \n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if bool(matched) :\n",
    "            matched_pattern = ptrn_name\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # Extracts sample information\n",
    "\n",
    "    if matched_pattern == \"illumina\":\n",
    "        file_name, sample_name, sample_id, read_num, lane, tail, ext = matched.groups()[0], matched.groups()[1], matched.groups()[2], matched.groups()[5], matched.groups()[4], matched.groups()[6], matched.groups()[7]\n",
    "\n",
    "    elif matched_pattern == \"SRR\":\n",
    "        file_name, sample_name, sample_id, read_num, lane, tail, ext = matched.groups()[0], matched.groups()[1], matched.groups()[3], matched.groups()[5], \"\", \"\", matched.groups()[6]\n",
    "\n",
    "    elif matched_pattern == \"general\":\n",
    "        file_name, sample_name, sample_id, read_num, lane, tail, ext = matched.groups()[0], matched.groups()[1], matched.groups()[1], matched.groups()[4], \"\", \"\", matched.groups()[5]\n",
    "\n",
    "    else:\n",
    "        file_name = sample_name = sample_id = read_num = lane = tail = ext = None\n",
    "\n",
    "    # Returns a dictionary of sample information\n",
    "    return {\n",
    "        \"file_name\": file_name,\n",
    "        \"sample_name\": sample_name,\n",
    "        \"sample_id\": sample_id,\n",
    "        \"read_num\": read_num,\n",
    "        \"lane\": lane,\n",
    "        \"tail\": tail,\n",
    "        \"ext\": ext,\n",
    "        \"matched_pattern\": ptrn_name\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_samples(inpath):\n",
    "    path = os.path.abspath(inpath)\n",
    "    all_files = os.listdir(path)\n",
    "    samples = defaultdict(dict)\n",
    "\n",
    "    for file_name in all_files:\n",
    "        if os.path.isfile(path + \"/\" + file_name) and (\"fastq\" in file_name or \"fq\" in file_name):\n",
    "            # Captures the file path and name\n",
    "            filename, file_extension = os.path.splitext(file_name)\n",
    "            if \"fastq\" in filename or \"fq\" in filename:\n",
    "                filename, new_ext = os.path.splitext(filename)\n",
    "                file_extension = new_ext + file_extension\n",
    "            sample_info = recogize_pattern(file_name)\n",
    "            if \"1\" in sample_info[\"read_num\"]:\n",
    "                read_2 = sample_info[\"read_num\"].replace(\"1\",\"2\")\n",
    "                if sample_info[\"matched_pattern\"] == \"illumina\":\n",
    "                    read_1 = f\"{sample_info['read_num']}_{sample_info['tail']}.f\"\n",
    "                    read_2 = f\"{read_2}_{sample_info['tail']}.f\"\n",
    "                else:\n",
    "                    read_1 = f\"{sample_info['read_num']}.f\"\n",
    "                    read_2 = f\"{read_2}.f\"\n",
    "\n",
    "                f2 = file_name.replace(read_1, read_2)\n",
    "                if f2 in all_files:\n",
    "                    sample_info[\"file2\"] = f2\n",
    "                    sample_info[\"PE\"] = True\n",
    "                    samples[sample_info[\"sample_id\"]] = sample_info\n",
    "\n",
    "                else:\n",
    "                    sample_info[\"file2\"] = \"\"\n",
    "                    sample_info[\"PE\"] = False\n",
    "                    print(f\"{RED}GUAP doesn't support single ended analysis at the moment{NC}\")\n",
    "                    exit(1)\n",
    "\n",
    "    m_samples = samples\n",
    "    samples= pd.DataFrame(samples).T\n",
    "    samples = samples.sort_values(by=['sample_id'])\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = parse_samples(\"/home/abdelrahman/Desktop/RNAseq/data/samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = str(check_pattern(samples)[0])\n",
    "ext = str(check_extension(samples)[0])\n",
    "PE = bool(check_PE(samples))\n",
    "R = str(check_R(samples)[0])\n",
    "compressed = False\n",
    "EXT = ext\n",
    "\n",
    "\n",
    "# to perform gunzipping \n",
    "if \".gz\" in ext:\n",
    "    compressed = True\n",
    "    EXT = ext.replace(\".gz\",\"\")\n",
    "\n",
    "\n",
    "\n",
    "# check if analysis run before and created sample table \n",
    "if os.path.exists(outpath+\"/\"+\"samples.tsv\"):\n",
    "    logging.warning(f\"\\033[;33;1mFound an exsiting sample.tsv file in output directory, will not override.\\033[;39;m\")\n",
    "else:\n",
    "    samples.to_csv(outpath+\"/\"+\"samples.tsv\",sep='\\t')    \n",
    "\n",
    "# create config file \n",
    "with open('config.yaml', 'w') as yaml_file:\n",
    "    yaml.safe_dump(vars(args), yaml_file, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "with open('config.yaml', 'a') as yaml_file:\n",
    "    yaml_file.writelines(f\"path: {path}\\n\")\n",
    "    yaml_file.writelines(f\"working_dir: {outpath}\\n\")\n",
    "    yaml_file.writelines(f\"ext: {ext}\\n\")\n",
    "    yaml_file.writelines(f\"tail: {tail}\\n\")\n",
    "    yaml_file.writelines(f\"R: {R}\\n\")\n",
    "    yaml_file.writelines(f\"R1_pattern: _{R}1{tail}{EXT}\\n\")\n",
    "    yaml_file.writelines(f\"R2_pattern: _{R}2{tail}{EXT}\\n\")\n",
    "    yaml_file.writelines(f\"compressed: {compressed}\\n\")\n",
    "    yaml_file.writelines(f\"total_mem: {all_mem}\\n\")\n",
    "    yaml_file.writelines(f\"GUAP_DIR: {GUAP_DIR}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from .globals import *\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, verbose=False):\n",
    "        self.formatter = logging.Formatter('[%(asctime)s] %(levelname)s: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        # define console handler\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setFormatter(self.formatter)\n",
    "        self.logger = logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "        # add the file handler to the logger\n",
    "        self.logger.addHandler(console_handler)\n",
    "        # set the logging level based on verbose argument\n",
    "        if verbose:\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "        \n",
    "\n",
    "        # define logging methods with color codes\n",
    "        self.prnt_info = lambda str: self.logger.info(f\"{GRY}{str}{NC}\")\n",
    "        self.prnt_warning = lambda str: self.logger.warning(f\"{YEL}{str}{NC}\")\n",
    "        self.prnt_error = lambda str: self.logger.error(f\"{RED}{str}{NC}\")\n",
    "\n",
    "    def add_file_handler(self, file_dir):\n",
    "        # create a file handler\n",
    "        file_handler = logging.FileHandler(file_dir)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "        # create a formatter and set it on the file handler\n",
    "        file_handler.setFormatter(self.formatter)\n",
    "\n",
    "        # add the file handler to the logger\n",
    "        self.logger.addHandler(file_handler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
